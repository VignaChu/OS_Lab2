# 练习1：理解first-fit 连续物理内存分配算法

## 核心数据结构
FFMA的实现主要依赖于以下数据结构：
- `struct Page`：代表物理页框，包含多个成员：
  - `page_link`：将空闲块的起始页链接到空闲列表；
  - `property`：仅在空闲块的起始页上有效，记录了该连续空闲块包含的页数$N$；
  - `flags`：用于标记该页是否为空闲块的起始页。
- `free_list`：全局双向链表头，用于按物理地址顺序管理所有连续的空闲内存块；
- `nr_free`：记录当前系统中所有空闲页框的总数。

## 物理内存分配过程
**整个物理内存分配过程由以下四个核心函数协同完成：**
1. `default_init`：
    - **作用**：初始化 First-Fit 内存管理器；
    - **实现过程**：
      - 通过 `list_init(&free_list)` 初始化用于管理空闲块的双向链表头;
      - 将 `nr_free`初始化为 0
2. `default_init_memmap`：
   1. **作用**：将一块新识别的连续物理内存区域（从 base 开始，共 n 页）作为初始空闲块加入管理。
   2. **实现过程**：
      1. **页初始化**：首先遍历`base`到`base+n-1`的所有页，清除其`flags`和 `property`，并将引用计数`ref`设为0。
      2. **设置起始页**：设置`base->property = n`，并设置`base`的 `PG_property`标志。
      3. **更新统计**：更新 `nr_free += n`。
      4. **插入链表**：将`base`的`page_link`结构按物理地址递增的顺序插入到`free_list`中。这是确保分配和合并操作效率的关键。
3. `default_alloc_pages`：
   1. **作用**：实现`First-Fit`算法，分配$n$个连续的物理页框。
   2. **实现过程**：
      1. **遍历查找**：从`free_list`头部开始顺序遍历，查找第一个空闲块$p$，满足 $p \rightarrow property \ge n$。
      2. **块分割**:
         - 找到满足条件的块 $p$ 后，首先将其从`free_list`中移除
         - 如果 $p \rightarrow property > n$（即块大小大于请求大小）：
           - 计算剩余空闲页的起始页 $p_{new} = p + n$，其大小为 $p \rightarrow property - n$
           - 将 $p_{new}$ 设置为新的空闲块起始页，并将其重新插入到 free_list 中（插入位置在原 $p$ 的位置）。
      3. **返回**：更新`nr_free -= n`，清除$p$的`PG_property`标志，并返回分配到的起始页$p$。
4. `default_free_pages`:
   - **作用**：释放从 base 开始的 $n$ 个连续页框，并尝试与相邻的空闲块进行合并。
   - **实现过程**：
     1. **初始化新空闲块**：将`base`到`base + n - 1`的页初始化，设置 `base->property = n`，设置`PG_property`标志，并更新`nr_free += n`。
     2. **有序插入**：将新空闲块`base`按物理地址顺序插入到`free_list`中。
     3. **尝试向前合并**：检查新插入块`base`的前一个空闲块$p_{prev}$。
        - **条件**：如果$p_{prev} + p_{prev} \rightarrow property == base$，则将两者合并。将$p_{prev} \rightarrow property$增加 `base->property`，并从链表中删除`base`。
     4. **尝试向后合并**：检查 base（或合并后的新块）的后一个空闲块 $p_{next}$。
        - **条件**：如果$base + base \rightarrow property == p_{next}$，则将两者合并。将`base->property`增加$p_{next} \rightarrow property$，并从链表中删除 $p_{next}$。
## 算法的改进空间
**本实验中的First-Fit的算法还有很大的改进空间，具体如下表所示**
| 改进方向 | 改进策略 | 优点 | 缺点/适用性 |
| :--- | :--- | :--- | :--- |
| **分配策略** | **Best-Fit 算法** | 尽量分配大小最接近需求的空闲块，减少内部碎片。 | 需要遍历整个空闲列表，搜索时间增加；倾向于产生大量小的外部碎片。 |
| **分配策略** | **Next-Fit 算法** | 从上次分配结束的位置开始搜索，而非总是从列表头开始。 | 搜索分布更均匀，可能略微提高搜索效率，但碎片问题未根本解决。 |
| **数据结构** | **分离空闲列表 (Segregated Lists)** | 为不同大小的空闲块维护独立的链表，加速查找。 | 复杂度增加，实现更复杂。 |
| **碎片管理** | **伙伴系统 (Buddy System)** | 强制空闲块大小为 $2^k$，利用伙伴块机制高效合并和分裂内存。 | 分配和释放的时间复杂度为 $O(\log N)$；可能引入**内部碎片**（由于大小必须向上取整）。 |

# 练习2： 实现 Best-Fit 连续物理内存分配算法

## 算法原理
1. **分配原则**:Best-Fit通过**遍历**整个空闲块列表，寻找所有够大的空闲块中最**接近**请求尺寸的块。
2. **优点**:倾向于使用**更小**且够用的块，从而避免将大块空闲内存分割成小块，从而能够表留更大的连续空间给需要更大空间的进程，避免**碎片**的产生。
3. **缺点**:必须先对整个列表进行遍历，效率低于简单的First-Fit，同时会产生**极小**的碎片化空间。

## 所用数据结构
- `struct Page`：代表物理页框，包含多个成员：
  - `page_link`：将空闲块的起始页链接到空闲列表；
  - `property`：仅在空闲块的起始页上有效，记录了该连续空闲块包含的页数$N$；
  - `PG_property`：用于标记该页是否为空闲块的起始页。
- `free_list`：全局双向链表头，用于按**物理地址顺序**管理所有连续的空闲内存块；

## 算法实现
本算法通过修改原有First-Fit算法的`default_alloc_pages`函数，从而实现了Best-Fit算法。


代码实现
```c
static struct Page *
best_fit_alloc_pages(size_t n) {
    assert(n > 0);
    if (n > nr_free) {
        return NULL;
    }

    // 引入两个新变量：用于记录找到的最佳匹配块及其大小
    struct Page *best_fit_page = NULL;
    size_t min_property = (size_t)-1; // 初始化为最大值

    list_entry_t *le = &free_list;
    // 1. 遍历整个空闲列表，寻找 Best-Fit 块
    while ((le = list_next(le)) != &free_list) {
        struct Page *p = le2page(le, page_link);
        
        // 检查当前空闲块 p 是否最合适
        if (p->property >= n && p->property < min_property) {
            min_property = p->property;
            best_fit_page = p;
        }
    }

    // 2. 如果找到了 Best-Fit 块
    if (best_fit_page != NULL) {
        struct Page *page = best_fit_page;
        
        // 3. 将 Best-Fit 块从链表中移除
        list_entry_t* prev = list_prev(&(page->page_link));
        list_del(&(page->page_link));

        // 4. 分裂：如果 Best-Fit 块有剩余空间，将分裂出的碎片插回原位
        if (page->property > n) {
            struct Page *p_new_free = page + n;
            p_new_free->property = page->property - n;
            SetPageProperty(p_new_free);

            list_add(prev, &(p_new_free->page_link));
        }
        
        // 5. 更新统计数据，并返回分配的页
        nr_free -= n;
        ClearPageProperty(page);
        
        return page;
    }
    
    return NULL;
}
```

此外本实验为了实现代码的稳健性，还修改了以下内容：
- `best_fit_init_memmap`：添加了对页面清空标志和引用计数归零的操作
- `best_fit_free_pages`：设置被释放页块的`property`、设置`PageProperty`标志以及更新`nr_free`的操作;bing将局部变量声明移动到goto标签之前


### 修改内容

1. 引入辅助变量：
   - `struct Page *best_fit_page = NULL;`:记录目前最符合块的起始位置；
   - `size_t min_property = (size_t)-1;`:记录当前最符合块的大小，默认为最大值，当找到更符合得块时进行更新；
2. 修改方法退出时机：
   - `First-Fit`:只要有可以放的下进程的内存块就放
   - `Best-Fit`:必须遍历整个空闲块列表才将进程放到记录的最符合块中
3. 修改内存块选择逻辑：
   - 循环内部的条件判断由*只要能放得下就退出*变为`if (p->property >= n && p->property < min_property)`，即*遍历全部以找到最合适的块*，这确保了只有当块$p$足够大并且比目前找到的任何块都更小时，才更改`best_fit_page`。

### 复杂度分析

### 比较 default_alloc_pages 的时间复杂度

假设M是当前空闲链表中空闲内存块的总数。

| 算法 | First-Fit| Best-Fit| 
| :--- | :--- | :--- |
| **最坏情况复杂度** | O(M) | **O(M)** |
| **平均情况复杂度** | 接近 O(1) 到 O(M/2)| **O(M)** |
| **查找逻辑** | 找到第一个满足条件的块，立即停止。 | 必须遍历所有 M 个块，以找到大小最接近请求的块。 |
| **主要性能差异** | *查找速度快*：平均性能高，因为搜索提前终止。 | **查找速度慢**：强制进行全面搜索，平均性能低于 FF。 |
---

### 结果检测

<img src="./picture/2的检验.png" style="width:10cm !important; height:4cm !important;">
<p style="color:gray">图1：Best-Fit算法正确性检测</p>

*图片表明本程序成功通过了验证*
## 改进空间

虽然`Best-Fit`算法能够有效的减少内部空间，但仍有存在着很多问题：
- **分配效率低下**:每次进行分配都*必须*先对整个空闲列表进行一次**遍历**，增加了额外的开销，导致效率降低。
  
- **空闲碎块积累**：由于Best-Fit算法会优先将最小的满足条件空闲块分配给进程，导致会产生很多**细小**的*碎片*化的空闲空间，且由于**数量众多**但**单个极小**，导致**大量**的空间无法被利用，从而导致空间的浪费。

可以考虑使用以下策略来对原有的Best-Fit算法进行优化：

| 改进方向 | 改进策略 | 目的/优势 |
| :--- | :--- | :--- |
| **分配效率** | **分离空闲列表 (Segregated Free Lists)** | 将不同大小（或大小范围）的空闲块放入独立的链表或数组中。分配时只需搜索特定大小范围的列表，大幅提高搜索速度（接近 $O(1)$ 或 $O(\log N)$）。 |
| **碎片管理** | **伙伴系统 (Buddy System)** | 一种更先进的算法，强制空闲块大小为 $2^k$。其高效的合并机制（合并时间复杂度 $O(\log N)$）能最大限度地对抗外部碎片。 |
| **数据结构** | **基于树结构的空闲列表** | 使用平衡二叉搜索树（例如，按空闲块大小排序）来代替线性链表。这样可以快速找到大小满足 $n$ 且最小的空闲块，将查找时间降为 $O(\log N)$。 |

# 硬件的可用物理内存范围的获取方法

在计算机中，由于历史原因和硬件设计需求，内存空间通常被分割成多个区域：
- **可用RAM**：操作系统可以自由使用的空间；
- **保留区**：被固件、硬件占用或映射的区域，操作系统不能使用；
- **ACPI结构区**：用于存放ACPI 表的物理内存区间，存储系统参数；
- 以及其他...
在启动后，操作系统必须知道哪些物理地址可用、哪些物理地址被保留。但OS无法提前无法提前知道这些信息，只能通过一些方法来获取。

为了解决这一问题，

## 方法一：通过固件：
本类方法通过在操作系统内核开始运行之前引导加载程序与早期代码和固件(BIOS或UEFI)通信，获取系统内存布局信息。
### BIOS INT 15h E820 扩展内存查询功能：
1. **应用场景**：传统的x86/x64架构的系统；
2. **工作原理**：
   - 引导加载程序调用 BIOS 的 INT 15h 中断，使用 E820 功能号请求内存映射信息;
   - BIOS 响应请求并返回**内存映射表**;
   - 内存映射表包含一系列内存区域描述符，每个描述符包含起始地址、长度和类型（可用、保留等）;
   - 引导程序会反复调用该功能直到获取到整个内存映射；
### UEFI GetMemoryMap() 函数：
1. **应用场景**：现代x86/x64架构的系统，大部分ARM64、AArch64架构的系统；
2. **工作原理**：
   - 引导加载程序调用 UEFI 运行时服务 `GetMemoryMap()` 函数，请求内存映射信息;
   - UEFI 运行时服务解析 ACPI 表，获取内存映射表;
   - 内存映射表包含一系列内存区域描述符，每个描述符包含起始地址、长度和类型（可用、保留等）;
   - 引导程序会反复调用`ExitBootServices`直到获取到整个内存映射；
### ACPI
1. **应用场景**：所有支持ACPI的系统；
2. **工作原理**：
   - ACPI 表中包含一系列内存区域描述符，每个描述符包含起始地址、长度和类型（可用、保留等）;
   - 可以利用ACPI表中存储的信息来获取系统内存布局信息。
   - 固件在初始化的时候会用特定标记划分空间，其中标记为`ACPI Reclaimable`的可以进行回收，而标记为`ACPI NVS`的部分是固件用于电源管理的，不能回收与分配。
   - 此外ACPI还提供了SRAT表格，该表格明确列出所有的物理内存范围与其所属节点ID。
## 方法二：通过非固件方案：
### 物理内存探测
1. **应用场景**：教学操作系统、嵌入式原型系统以及无固件支持的裸机系统等
2. **工作原理**：
   - 操作系统按(＾－＾)V逐步向物理地址写入魔法值(通常为0xdeadbeef)再读回验证，若读回值一致则认为该页存在且可用；若不一致则或触发异常则认为该页无效
### 引导参数传递
- **应用场景**：固件不提供物理接口(如无ACPI)时
- **工作原理**：
  - Bootloader 在启动 OS 前，提前探测内存（可通过内存控制器、配置寄存器或探测法），然后将结果通过约定方式传递给内核。操作系统只需解析该结构体，无需再探测。
### 硬编码内存范围
- **应用场景**：教学实验仿真平台(如QEMU)
- **工作原理**：
  - 在编译的时候通过链接脚本或头文件直接写死内存起始地址与大小，操作系统直接调用这些常量初始化内存管理。无需探测。
### 异常驱动边界探测
- **应用场景**：极简内核，内存连续只需知道上限的场景。
- **工作原理**：OS从已知起始地址开始，不断向后尝试分配内存，直到触发异常或超出边界。

# 本实验中重要的知识点

## 物理内存与寻址基础
1. 物理地址：
   - **定义**：是内存单元的**实际地址**，由一系列存储单元构成。CPU通过地址总线能够直接访问到物理内存从而访问其中的数据。
   - **直接寻址**：在简单系统中，程序指令中的地址直接作为物理地址,被CPU发送到内存总线。
2. 寻址基础：**内存连续性**
   - 在没有地址转换机制时，程序所需的代码、数据和堆栈必须被分配到**连续且足够大的物理内存地址**才能运行
   - 这种苛刻的要求导致了一系列问题
## 多任务环境带来的核心问题
1. 地址空间冲突与内存保护：
   - **问题**：当多个执行实体(如多个用户程序)同时运行，如果他们的指令同时想访问同一个**物理位置**，则会发生冲突；
   - **后果**：一个程序的错误或恶意行为可能意外修改或破坏另一个程序（甚至是**操作系统内核**）的数据，导致系统不稳定或导致安全漏洞。
   - **解决**：通过引入机制实现内核空间与用户空间，以及用户程序彼此之间的**彻底隔离**。
2. 外部碎片化：
   - **定义**：由于对内存连续性的需求，随着程序不断加载和退出，物理内存会被分割成许多*不连续*的**小块空闲区域**；
   - **影响**：将系统中完整地1地址不断拆分直至*无法利用*，导致资源的浪费。
## 虚拟内存与地址翻译机制
1. 虚拟内存(VM)
   - **理念**：引入一层抽象，将**程序指令中的地址**与**真实的物理地址**解耦；
   - **目标**：实现地址空间隔离，让不同程序看到的地址映射到不同的物理位置，从而避免不同程序之间的**寻址冲突**；
2. 地址翻译
   - **定义**：将虚拟地址翻译为物理地址的过程，是虚拟内存的关键技术。
   - **实现**:通过页表、段表等实现，用于存储物理地址与虚拟地址之间的映射。通常每个进程拥有自己的表。
## 分页机制与内存配位粒度
1. 粒度问题
   - 如果对内存中的每个字节都进行独立的地址翻译，翻译表本身会占用与物理内存**同等甚至更多**的空间
2. 分页机制
   - **定义**:将连续的一组字节（通常为4KB）合并在一起，作为内存分配和翻译的基本单位。
   - **原理**：翻译只发生在地址的高位部分（虚拟页号），而地址的低位部分（页内偏移）在翻译前后保持不变（“翻译前后的数值之差相同”）。这使得一块连续的虚拟地址可以映射到不连续的物理页框（Page Frames），彻底消除了外部碎片问题。
   - **地址**：页的大小通常是4096B，其中低12 位用于表示页内偏移（$2^{12} = 4096$），高位则用于页号。
   - **页内偏移**：不论是物理地址还是虚拟地址，其最后 12 位都表示该地址在其所在页（或页框）中的相对位置。地址翻译只转换页号，**页内偏移保持不变**；
   - **页表**：页表是实现地址翻译的**数据结构**，存储了虚拟页号到物理页号的对应关系；
## Sv39 体系结构下的地址限制
1. **基本介绍**：Sv39 是 RISC-V 64 位处理器中最常用的一种分页式虚拟地址转换模式，名字里的 “39” 表示有效虚拟地址只有 39 位，其余高位必须做符号扩展。它把整个 64 位虚拟空间裁剪成 512 GB 大小，采用 三级页表完成 VA→PA 映射，一页 4 KB
2. **虚拟地址合法性检查**：规定地址的 $63 \sim 39$ 位的值必须等于第 $38$ 位（即最高有效位）的值。如果不满足这一规则，该虚拟地址被视为不合法，访问时会产生异常。
## 分页带来的优势
1. 编程抽象：程序员面对的是一个连续、统一的虚拟地址空间，无需关心底层物理内存的非连续性。将编程从底层的硬件管理中解放出来，简化了开发。
2. 多任务的隔离与共享
   - **隔离**：不同的程序可以使用相同的虚拟地址空间，但通过它们各自的页表映射到不同的物理地址，彻底避免了地址冲突。
   - **共享**： OS 可以通过设置多个页表项指向同一个物理页，方便地实现进程间的**内存共享**
3. 灵活内存管理：OS 可以通过修改页表（而非移动物理内存中的数据），轻松实现换页功能。即当物理内存不足时，将不常用的物理**页内容换出到磁盘**，并将对应的页表项标记为无效或指向磁盘位置。

## 从物理内存探测到虚拟内存启用

### 内存引导阶段的关键准备

#### 启动函数的修改与作用
- `kern_entry`：
  - **主要任务**：设置虚拟内存管理。将三级页表的物理地址和Sv39模式位写入`satp`寄存器;
  - **目标**建立内核的虚拟内存空间，为后续的分页机制运行做好硬件准备,激活**MMU**
- `kern_init`：
  - 在`kern_entry`完成虚拟内存准备后，调用`kern_init`,启动输出，并进行物理内存管理初始化与中断与异常初始化。
#### 物理内存管理初始化
1. 探测物理内存资源：探测系统可用的物理内存范围和大小，确定物理内存的布局。
2. 物理内存划分：以固定页面大小（4KB）来划分整个物理内存空间。对内核运行过程中每一页内存进行管理。
3. 状态管理：管理每页内存的可用状态
### 虚拟内存管理与分页机制的创立
1. 分页机制的启动：
   - **核心任务**：建立页表，并最终启动分页机制。
   - **硬件交互**:OS 建立好页表后，CPU 的 **MMU（内存管理单元）**将根据配置，把页表项读入 **TLB（转换后备缓冲区）**中.
2. 地址映射的实现：
   - **对应关系**： 页表项描述了**虚拟页（Page）与物理页帧（Page Frame）**的对应关系。
   - **CPU 操作**： CPU 依靠 TLB/页表完成对内存的读、写和执行操作时的地址转换。 。

##  页表项（PTE）的结构与功能

* **页表项（PTE）：**
    * **定义：** 存储在内存中的**词条**，用于描述**虚拟页号**到**物理页号**的对应关系。
    * **Sv39 结构：** 每个页表项占据 **8 字节 (64 位)**，具备固定格式。
    * **主要组成部分：**
        * **物理页号（PPN）：**占据$53 \sim 10$位，共$44$位，指示映射到的**物理页框地址**。
        * **状态信息：** 占据$9 \sim 0$位，描述映射的权限和状态。

## 映射状态信息的权限与标志位

* **许可位（R, W, X）：**
    * **R (Readable)：** 是否允许**读**操作。
    * **W (Writable)：** 是否允许**写**操作（`store` 指令）。若 $W=0$ 但尝试写入，将引发异常。
    * **X (Executable)：** 是否允许作为指令**执行**（取指）。
    * **特殊组合：** $R, W, X$ 全为 $0$ 时，表示该页表项是一个**指向下一级页表的指针**（内部节点）。其他 $0 \sim 7$ 的组合定义了页的权限。
* **状态标志位（A, D）：**
    * **A (Accessed)：** 置 $1$ 表示该页自上次清零后被**访问过**（读、写、取指）。用于**换页算法**判断页的活跃性。
    * **D (Dirty)：** 置 $1$ 表示该页自上次清零后被**写入过**。用于**写回策略**（换页时如果 $D=0$，则无需写回磁盘）。
* **特权级控制（U, G）：**
    * **U (User)：** 置 $1$ 表示该页允许**用户态（U Mode）**程序访问。用户态程序**只允许**访问 $U=1$ 的页面。
    * **SUM 位（Supervisor User Memory）：** S Mode 默认不能访问 $U=1$ 的页面。只有手动将 `sstatus` 寄存器的 **SUM 位设为 $1$** 时，S Mode 才能访问用户页。但出于安全，S Mode **不允许执行** $U=1$ 页面中的指令。
    * **G (Global)：** 置 $1$ 表示该页表项是**“全局”**的，所有地址空间都包含这一项。常用于内核关键代码和数据的映射，避免地址空间切换时被 TLB 刷新。
* **V (Valid)：**
    * 置 $1$ 表示该页表项**合法有效**；置 $0$ 时，其余位信息将被忽略。常用于**换页机制**。

## 多级页表与地址空间扩展

* **引入多级页表的原因：**
    * **虚拟地址空间巨大：** Sv39 拥有 $2^{27}$ 个虚拟页号，若采用单级页表，需 $2^{27} \times 8$ 字节 $\approx 1 \text{GiB}$ 内存来存储页表项。
    * **稀疏性问题：** 许多虚拟地址空间未被使用，会导致大量页表项的 $V=0$（不合法），浪费宝贵的物理内存。
* **树状结构与按需分配：**
    * **分级原理：** 将页表组织成**树状结构**（多级页表），只为**有效映射的区域**建立下级页表。如果一大片虚拟地址都未被使用，则只需一个**非法**的父级页表项即可，节省大量内存。
* **Sv39 的三级页表结构：**
    * **层数：** 使用**三级页表**（权衡了寻址开销和空间节省）。
    * **地址划分：** 39 位虚拟地址划分为 $9$ 位（三级/根目录索引）、$9$ 位（二级/大大页索引）、$9$ 位（一级/大页索引）和 $12$ 位（页内偏移）。
    * **页目录大小：** 每页 $4 \text{KiB}$ / $8$ 字节（PTE 大小） $= 512$ 个页表项，恰好对应 $2^9$。
    * **地址空间容量：** $512^3 \times 4 \text{KiB} \approx 512 \text{GiB}$ 的虚拟地址空间。

## 大/巨页映射

* **大/巨页映射（Mega/Giga Page）：**
    * **原理：** 三级和二级页表项的 $R, W, X$ 许可位可以设置为**非全 $0$**。
    * **功能：** 此时，它们不再指向下一级页表，而是直接充当**叶子节点**，映射一个大块的物理内存区域：
        * **二级 PTE：** 映射 $2 \text{MiB}$ 的**大页（Mega Page）**。
        * **三级 PTE：** 映射 $1 \text{GiB}$ 的**巨页（Giga Page）**。
    * **优势：** 减少页表级数，降低 MMU 寻址开销，提升 TLB 命中率，优化大内存块的性能。

## 硬件寄存器与地址空间切换

* **`satp` 寄存器（Supervisor Address Translation and Protection Register）：**
    * **功能：** 用于保存**树状页表根节点的物理页号（PPN）**，以及当前地址翻译的**模式信息**。
    * **地址转换的起点：** CPU/MMU 在地址翻译时，从 `satp` 中获取最高级页表的起始地址。
* **模式（MODE）：**
    * **$0000$：** 不使用页表，直接使用物理地址（**直通映射**）。
    * **$1000$ (Sv39)：** 启用三级页表模式。
* **地址空间切换：**
    * OS 通过修改 `satp` 寄存器的值来指向**不同应用（进程）的页表**，从而**修改 CPU 的虚实地址映射关系**，实现进程间的地址空间切换和内存保护。
    * **ASID (Address Space Identifier)：** 虽然文本提到目前用不到，但在多任务 OS 中，ASID 用于帮助 TLB 区分不同进程的映射项，减少上下文切换时的 TLB 刷新开销。
